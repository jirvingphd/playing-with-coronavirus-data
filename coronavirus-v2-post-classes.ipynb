{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playing with Coronavirus Timeseries\n",
    "\n",
    "- https://www.kaggle.com/sudalairajkumar/novel-corona-virus-2019-dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This notebook uses 2 classes (based on a BaseDataset class) to load in data from both a kaggle dataset (novel coronavirus 2019) and the Covid Tracking Project data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To Do:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] Add data from Covid Tracking Project's API\n",
    "    - https://covidtracking.com/api\n",
    "    \n",
    "- [ ] Move app styling to a css file in a new `assets/` folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Functions and classes are in functions.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RESOURCES FOR FUTURE\n",
    "- RAFAEL STUDY GROUP FOR MAKING A MAP\n",
    "    - https://www.youtube.com/watch?v=MAhK7NHXEOg&feature=emb_logo\n",
    "    - https://github.com/erdosn/additional-topic-plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-03T19:24:54.155810Z",
     "start_time": "2020-07-03T19:24:46.118758Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "pio.templates.default = \"plotly_dark\"\n",
    "\n",
    "import cufflinks as cf\n",
    "cf.go_offline()\n",
    "cf.set_config_file(sharing='public',theme='solar',offline=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-03T19:24:57.248731Z",
     "start_time": "2020-07-03T19:24:54.157320Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: fsds in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (0.2.16)\n",
      "Requirement already satisfied, skipping upgrade: IPython in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from fsds) (7.8.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.18 in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from fsds) (1.18.4)\n",
      "Requirement already satisfied, skipping upgrade: matplotlib>=3.2.0 in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from fsds) (3.2.1)\n",
      "Requirement already satisfied, skipping upgrade: pandas>1.0.0 in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from fsds) (1.0.4)\n",
      "Requirement already satisfied, skipping upgrade: ipywidgets in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from fsds) (7.5.1)\n",
      "Requirement already satisfied, skipping upgrade: missingno in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from fsds) (0.4.2)\n",
      "Requirement already satisfied, skipping upgrade: seaborn in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from fsds) (0.10.1)\n",
      "Requirement already satisfied, skipping upgrade: scipy in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from fsds) (1.3.1)\n",
      "Requirement already satisfied, skipping upgrade: pprint in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from fsds) (0.1)\n",
      "Requirement already satisfied, skipping upgrade: wordcloud in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from fsds) (1.7.0)\n",
      "Requirement already satisfied, skipping upgrade: tzlocal in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from fsds) (2.1)\n",
      "Requirement already satisfied, skipping upgrade: cufflinks in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from fsds) (0.17.3)\n",
      "Requirement already satisfied, skipping upgrade: pyperclip in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from fsds) (1.8.0)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn>=0.23.1 in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from fsds) (0.23.1)\n",
      "Requirement already satisfied, skipping upgrade: pandas-profiling in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from fsds) (2.8.0)\n",
      "Requirement already satisfied, skipping upgrade: jedi>=0.10 in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from IPython->fsds) (0.15.1)\n",
      "Requirement already satisfied, skipping upgrade: pickleshare in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from IPython->fsds) (0.7.5)\n",
      "Requirement already satisfied, skipping upgrade: appnope; sys_platform == \"darwin\" in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from IPython->fsds) (0.1.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=18.5 in /Users/jamesirving/.local/lib/python3.6/site-packages (from IPython->fsds) (46.1.2)\n",
      "Requirement already satisfied, skipping upgrade: decorator in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from IPython->fsds) (4.4.0)\n",
      "Requirement already satisfied, skipping upgrade: prompt-toolkit<2.1.0,>=2.0.0 in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from IPython->fsds) (2.0.9)\n",
      "Requirement already satisfied, skipping upgrade: traitlets>=4.2 in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from IPython->fsds) (4.3.2)\n",
      "Requirement already satisfied, skipping upgrade: pygments in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from IPython->fsds) (2.4.2)\n",
      "Requirement already satisfied, skipping upgrade: backcall in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from IPython->fsds) (0.1.0)\n",
      "Requirement already satisfied, skipping upgrade: pexpect; sys_platform != \"win32\" in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from IPython->fsds) (4.7.0)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from matplotlib>=3.2.0->fsds) (2.8.0)\n",
      "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from matplotlib>=3.2.0->fsds) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from matplotlib>=3.2.0->fsds) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from matplotlib>=3.2.0->fsds) (2.4.2)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from pandas>1.0.0->fsds) (2019.2)\n",
      "Requirement already satisfied, skipping upgrade: widgetsnbextension~=3.5.0 in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from ipywidgets->fsds) (3.5.1)\n",
      "Requirement already satisfied, skipping upgrade: nbformat>=4.2.0 in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from ipywidgets->fsds) (4.4.0)\n",
      "Requirement already satisfied, skipping upgrade: ipykernel>=4.5.1 in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from ipywidgets->fsds) (5.1.2)\n",
      "Requirement already satisfied, skipping upgrade: pillow in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from wordcloud->fsds) (6.1.0)\n",
      "Requirement already satisfied, skipping upgrade: plotly>=4.1.1 in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from cufflinks->fsds) (4.8.1)\n",
      "Requirement already satisfied, skipping upgrade: colorlover>=0.2.1 in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from cufflinks->fsds) (0.3.0)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.9.0 in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from cufflinks->fsds) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from scikit-learn>=0.23.1->fsds) (0.13.2)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from scikit-learn>=0.23.1->fsds) (2.0.0)\n",
      "Requirement already satisfied, skipping upgrade: astropy>=4.0 in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from pandas-profiling->fsds) (4.0.1.post1)\n",
      "Requirement already satisfied, skipping upgrade: requests>=2.23.0 in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from pandas-profiling->fsds) (2.23.0)\n",
      "Requirement already satisfied, skipping upgrade: tqdm>=4.43.0 in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from pandas-profiling->fsds) (4.46.0)\n",
      "Requirement already satisfied, skipping upgrade: phik>=0.9.10 in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from pandas-profiling->fsds) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: visions[type_image_path]==0.4.4 in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from pandas-profiling->fsds) (0.4.4)\n",
      "Requirement already satisfied, skipping upgrade: confuse>=1.0.0 in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from pandas-profiling->fsds) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: htmlmin>=0.1.12 in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from pandas-profiling->fsds) (0.1.12)\n",
      "Requirement already satisfied, skipping upgrade: tangled-up-in-unicode>=0.0.6 in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from pandas-profiling->fsds) (0.0.6)\n",
      "Requirement already satisfied, skipping upgrade: jinja2>=2.11.1 in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from pandas-profiling->fsds) (2.11.2)\n",
      "Requirement already satisfied, skipping upgrade: parso>=0.5.0 in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from jedi>=0.10->IPython->fsds) (0.5.1)\n",
      "Requirement already satisfied, skipping upgrade: wcwidth in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from prompt-toolkit<2.1.0,>=2.0.0->IPython->fsds) (0.1.7)\n",
      "Requirement already satisfied, skipping upgrade: ipython_genutils in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from traitlets>=4.2->IPython->fsds) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: ptyprocess>=0.5 in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from pexpect; sys_platform != \"win32\"->IPython->fsds) (0.6.0)\n",
      "Requirement already satisfied, skipping upgrade: notebook>=4.4.1 in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from widgetsnbextension~=3.5.0->ipywidgets->fsds) (5.7.8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied, skipping upgrade: jupyter-core in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from nbformat>=4.2.0->ipywidgets->fsds) (4.5.0)\n",
      "Requirement already satisfied, skipping upgrade: jsonschema!=2.5.0,>=2.4 in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from nbformat>=4.2.0->ipywidgets->fsds) (3.0.2)\n",
      "Requirement already satisfied, skipping upgrade: tornado>=4.2 in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from ipykernel>=4.5.1->ipywidgets->fsds) (6.0.3)\n",
      "Requirement already satisfied, skipping upgrade: jupyter-client in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from ipykernel>=4.5.1->ipywidgets->fsds) (5.3.3)\n",
      "Requirement already satisfied, skipping upgrade: retrying>=1.3.3 in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from plotly>=4.1.1->cufflinks->fsds) (1.3.3)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from requests>=2.23.0->pandas-profiling->fsds) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from requests>=2.23.0->pandas-profiling->fsds) (1.24.2)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from requests>=2.23.0->pandas-profiling->fsds) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from requests>=2.23.0->pandas-profiling->fsds) (2020.6.20)\n",
      "Requirement already satisfied, skipping upgrade: numba>=0.38.1 in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from phik>=0.9.10->pandas-profiling->fsds) (0.49.1)\n",
      "Requirement already satisfied, skipping upgrade: attrs>=19.3.0 in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from visions[type_image_path]==0.4.4->pandas-profiling->fsds) (19.3.0)\n",
      "Requirement already satisfied, skipping upgrade: networkx>=2.4 in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from visions[type_image_path]==0.4.4->pandas-profiling->fsds) (2.4)\n",
      "Requirement already satisfied, skipping upgrade: imagehash; extra == \"type_image_path\" in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from visions[type_image_path]==0.4.4->pandas-profiling->fsds) (4.1.0)\n",
      "Requirement already satisfied, skipping upgrade: pyyaml in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from confuse>=1.0.0->pandas-profiling->fsds) (5.3.1)\n",
      "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from jinja2>=2.11.1->pandas-profiling->fsds) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: nbconvert in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->fsds) (5.5.0)\n",
      "Requirement already satisfied, skipping upgrade: terminado>=0.8.1 in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->fsds) (0.8.2)\n",
      "Requirement already satisfied, skipping upgrade: prometheus-client in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->fsds) (0.7.1)\n",
      "Requirement already satisfied, skipping upgrade: pyzmq>=17 in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->fsds) (18.1.0)\n",
      "Requirement already satisfied, skipping upgrade: Send2Trash in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->fsds) (1.5.0)\n",
      "Requirement already satisfied, skipping upgrade: pyrsistent>=0.14.0 in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->fsds) (0.14.11)\n",
      "Requirement already satisfied, skipping upgrade: llvmlite<=0.33.0.dev0,>=0.31.0.dev0 in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from numba>=0.38.1->phik>=0.9.10->pandas-profiling->fsds) (0.32.1)\n",
      "Requirement already satisfied, skipping upgrade: PyWavelets in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from imagehash; extra == \"type_image_path\"->visions[type_image_path]==0.4.4->pandas-profiling->fsds) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: pandocfilters>=1.4.1 in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->fsds) (1.4.2)\n",
      "Requirement already satisfied, skipping upgrade: bleach in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->fsds) (3.1.5)\n",
      "Requirement already satisfied, skipping upgrade: defusedxml in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->fsds) (0.6.0)\n",
      "Requirement already satisfied, skipping upgrade: entrypoints>=0.2.2 in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->fsds) (0.3)\n",
      "Requirement already satisfied, skipping upgrade: mistune>=0.8.1 in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->fsds) (0.8.4)\n",
      "Requirement already satisfied, skipping upgrade: testpath in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->fsds) (0.4.2)\n",
      "Requirement already satisfied, skipping upgrade: packaging in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->fsds) (20.4)\n",
      "Requirement already satisfied, skipping upgrade: webencodings in /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->fsds) (0.5.1)\n"
     ]
    }
   ],
   "source": [
    "import os,glob,sys\n",
    "import re\n",
    "\n",
    "!pip install -U fsds\n",
    "from fsds.imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-03T19:24:57.300925Z",
     "start_time": "2020-07-03T19:24:57.250773Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import functions as fn\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-03T19:24:57.353692Z",
     "start_time": "2020-07-03T19:24:57.302463Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module functions:\n",
      "\n",
      "NAME\n",
      "    functions - module(name[, doc])\n",
      "\n",
      "DESCRIPTION\n",
      "    Create a module object.\n",
      "    The name must be a string; the optional doc argument can have any type.\n",
      "\n",
      "CLASSES\n",
      "    builtins.object\n",
      "        BaselineData\n",
      "            CoronaData\n",
      "            CovidTrackingProject\n",
      "    \n",
      "    class BaselineData(builtins.object)\n",
      "     |  #Make a base class\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  get_group_ts(self, group_name, group_col='state', ts_col=None, df=None, freq='D', agg_func='sum')\n",
      "     |      Take df_us and extracts state's data as then Freq/Aggregation provided\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  df\n",
      "    \n",
      "    class CoronaData(BaselineData)\n",
      "     |  Dataset from the Novel Coronavirus Kaggle repo\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      BaselineData (Base Class)\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      CoronaData\n",
      "     |      BaselineData\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, data_dir='New Data/', run_workflow=True, download=True, verbose=True)\n",
      "     |      [summary]\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          data_dir (str, optional): [description]. Defaults to 'New Data/'.\n",
      "     |          run_workflow (bool, optional): [description]. Defaults to True.\n",
      "     |          download (bool, optional): [description]. Defaults to True.\n",
      "     |          verbose (bool, optional): [description]. Defaults to True.\n",
      "     |  \n",
      "     |  calculate_per_capita(self, df_=None, stat_cols=['Confirmed', 'Deaths', 'Recovered'])\n",
      "     |      Calculate Per Capita columns\n",
      "     |  \n",
      "     |  download_coronavirus_data(self, path=None, verbose=None)\n",
      "     |      Installs the Kaggle Command Line Interface to clone dataset.\n",
      "     |      Then extracts dataset to specified path and displays name of main file.\n",
      "     |      Args:\n",
      "     |          path(str): Folder to extract dataset into (must end with a '/')\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          file_list(list): List of full filepaths to downloaded csv files.\n",
      "     |  \n",
      "     |  get_and_clean_US(self, df=None, make_date_index=True, per_capita=True)\n",
      "     |      Takes raw df loaded and extracts United States and processes\n",
      "     |      all state names to create new abbreviation column 'state'.\n",
      "     |  \n",
      "     |  get_data_fpath(self, path)\n",
      "     |      save self._file_list and self._main_file\n",
      "     |  \n",
      "     |  load_raw_df(self, fpath=None, kws={}, verbose=True)\n",
      "     |      Performs most basic of preprocessing, including renaming date column to \n",
      "     |      Date and dropping 'Last Update', and 'SNo' columns\n",
      "     |  \n",
      "     |  load_us_reference_info(self)\n",
      "     |      Return and save US Reference Data\n",
      "     |  \n",
      "     |  set_datetime_index(self, df_=None, col='Date')\n",
      "     |      Returns df with specified column as datetime index\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from BaselineData:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  get_group_ts(self, group_name, group_col='state', ts_col=None, df=None, freq='D', agg_func='sum')\n",
      "     |      Take df_us and extracts state's data as then Freq/Aggregation provided\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from BaselineData:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  df\n",
      "    \n",
      "    class CovidTrackingProject(BaselineData)\n",
      "     |  Method resolution order:\n",
      "     |      CovidTrackingProject\n",
      "     |      BaselineData\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, base_folder='New Data/', download=True, verbose=True, df_type='states')\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  download_state_daily(self)\n",
      "     |  \n",
      "     |  download_state_meta(self)\n",
      "     |  \n",
      "     |  download_us_daily(self)\n",
      "     |  \n",
      "     |  get_csv_save_load(self, url, fpath, read_kws={'parse_dates': ['date']})\n",
      "     |  \n",
      "     |  help(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  base_url = 'http://covidtracking.com'\n",
      "     |  \n",
      "     |  columns = {'deprecated': ['checkTimeEt', 'commercialScore', 'dateCheck...\n",
      "     |  \n",
      "     |  columns_us = {'deprecated': ['hospitalized', 'lastModified', 'total', ...\n",
      "     |  \n",
      "     |  urls = {'states': 'http://covidtracking.com/api/v1/states/daily.csv', ...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from BaselineData:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  get_group_ts(self, group_name, group_col='state', ts_col=None, df=None, freq='D', agg_func='sum')\n",
      "     |      Take df_us and extracts state's data as then Freq/Aggregation provided\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from BaselineData:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  df\n",
      "\n",
      "FUNCTIONS\n",
      "    download_coronavirus_data(path='New Data/', verbose=False)\n",
      "        Installs the Kaggle Command Line Interface to clone dataset.\n",
      "        Then extracts dataset to specified path and displays name of main file.\n",
      "        Args:\n",
      "            path(str): Folder to extract dataset into (must end with a '/')\n",
      "            \n",
      "        Returns:\n",
      "            file_list(list): List of full filepaths to downloaded csv files.\n",
      "    \n",
      "    get_state_ts(df, state_name, group_col='state', ts_col=None, freq='D', agg_func='sum')\n",
      "        Take df_us and extracts state's data as then Freq/Aggregation provided\n",
      "    \n",
      "    make_options(menu_choices)\n",
      "        Returns list of dictionary with {'label':menu_choice,'value':menu_choice}\n",
      "    \n",
      "    plot_states(df, state_list, plot_cols=['Confirmed'], df_only=False, new_only=False, plot_scatter=True, show=False)\n",
      "        Plots the plot_cols for every state in state_list.\n",
      "        Returns plotly figure\n",
      "        New as of 06/21\n",
      "\n",
      "FILE\n",
      "    /Users/jamesirving/Documents/GitHub/_MY_SIDE_PROJECTS/playing-with-coronavirus-data/functions.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Kaggle Dataset - Get US States"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📦class `CoronaData`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-03T19:24:57.397258Z",
     "start_time": "2020-07-03T19:24:57.354908Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from functions import BaselineData\n",
    "from functions import CoronaData\n",
    "# fs.ihelp(CoronaData,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-03T19:25:00.727464Z",
     "start_time": "2020-07-03T19:24:57.398614Z"
    },
    "code_folding": [],
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] DOWNLOADING DATA USING KAGGLE API\n",
      "\thttps://www.kaggle.com/sudalairajkumar/novel-corona-virus-2019-dataset\n",
      "\t- Downloaded dataset .zip and extracted to:\"New Data/\"\n",
      "\t- Extraction Complete.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Recovered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>Anhui</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>Chongqing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>Fujian</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>Gansu</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date Province/State  Country/Region  Confirmed  Deaths  Recovered\n",
       "0 2020-01-22          Anhui  Mainland China        1.0     0.0        0.0\n",
       "1 2020-01-22        Beijing  Mainland China       14.0     0.0        0.0\n",
       "2 2020-01-22      Chongqing  Mainland China        6.0     0.0        0.0\n",
       "3 2020-01-22         Fujian  Mainland China        1.0     0.0        0.0\n",
       "4 2020-01-22          Gansu  Mainland China        0.0     0.0        0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] There are 223 countries in the datatset\n",
      "[i] Dates Covered:\n",
      "\tFrom 01-22-2020 to 06-30-2020\n"
     ]
    }
   ],
   "source": [
    "corona = CoronaData(verbose=True,run_workflow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-03T19:25:00.776686Z",
     "start_time": "2020-07-03T19:25:00.728812Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "------------------------------------------------------------\n",
       "[i] CovidTrackingProject Contents:\n",
       "------------------------------------------------------------\n",
       "\n",
       "METHODS:\n",
       "\tcalculate_per_capita\n",
       "\tdownload_coronavirus_data\n",
       "\tget_and_clean_US\n",
       "\tget_data_fpath\n",
       "\tget_group_ts\n",
       "\tload_raw_df\n",
       "\tload_us_reference_info\n",
       "\tset_datetime_index\n",
       "\n",
       "ATTRIBUTES\n",
       "\tSTATES\n",
       "\tdf\n",
       "\tdf_us\n",
       "\traw_df\n",
       "\treference_data"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-03T19:25:00.847929Z",
     "start_time": "2020-07-03T19:25:00.778739Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SNo</th>\n",
       "      <th>ObservationDate</th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Last Update</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Recovered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>Anhui</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>2020-01-22 17:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>2020-01-22 17:00:00</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>Chongqing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>2020-01-22 17:00:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>Fujian</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>2020-01-22 17:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>Gansu</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>2020-01-22 17:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SNo ObservationDate Province/State  ... Confirmed Deaths  Recovered\n",
       "0    1      2020-01-22          Anhui  ...       1.0    0.0        0.0\n",
       "1    2      2020-01-22        Beijing  ...      14.0    0.0        0.0\n",
       "2    3      2020-01-22      Chongqing  ...       6.0    0.0        0.0\n",
       "3    4      2020-01-22         Fujian  ...       1.0    0.0        0.0\n",
       "4    5      2020-01-22          Gansu  ...       0.0    0.0        0.0\n",
       "\n",
       "[5 rows x 8 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corona.raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-03T19:25:00.916524Z",
     "start_time": "2020-07-03T19:25:00.850623Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Recovered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>Anhui</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>Chongqing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>Fujian</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>Gansu</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date Province/State  Country/Region  Confirmed  Deaths  Recovered\n",
       "0 2020-01-22          Anhui  Mainland China        1.0     0.0        0.0\n",
       "1 2020-01-22        Beijing  Mainland China       14.0     0.0        0.0\n",
       "2 2020-01-22      Chongqing  Mainland China        6.0     0.0        0.0\n",
       "3 2020-01-22         Fujian  Mainland China        1.0     0.0        0.0\n",
       "4 2020-01-22          Gansu  Mainland China        0.0     0.0        0.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corona.df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-03T19:25:00.985318Z",
     "start_time": "2020-07-03T19:25:00.917971Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Recovered</th>\n",
       "      <th>state</th>\n",
       "      <th>Confirmed Per Capita</th>\n",
       "      <th>Deaths Per Capita</th>\n",
       "      <th>Recovered Per Capita</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-22</th>\n",
       "      <td>Washington</td>\n",
       "      <td>US</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>1.313216e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-23</th>\n",
       "      <td>Washington</td>\n",
       "      <td>US</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>1.313216e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-24</th>\n",
       "      <td>Washington</td>\n",
       "      <td>US</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>1.313216e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-25</th>\n",
       "      <td>Washington</td>\n",
       "      <td>US</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>1.313216e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-26</th>\n",
       "      <td>Washington</td>\n",
       "      <td>US</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>1.313216e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Province/State  ... Recovered Per Capita\n",
       "Date                       ...                     \n",
       "2020-01-22     Washington  ...                  0.0\n",
       "2020-01-23     Washington  ...                  0.0\n",
       "2020-01-24     Washington  ...                  0.0\n",
       "2020-01-25     Washington  ...                  0.0\n",
       "2020-01-26     Washington  ...                  0.0\n",
       "\n",
       "[5 rows x 9 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corona.df_us.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-03T19:25:01.051491Z",
     "start_time": "2020-07-03T19:25:00.986942Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Recovered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>Anhui</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>Chongqing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>Fujian</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>Gansu</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date Province/State  Country/Region  Confirmed  Deaths  Recovered\n",
       "0 2020-01-22          Anhui  Mainland China        1.0     0.0        0.0\n",
       "1 2020-01-22        Beijing  Mainland China       14.0     0.0        0.0\n",
       "2 2020-01-22      Chongqing  Mainland China        6.0     0.0        0.0\n",
       "3 2020-01-22         Fujian  Mainland China        1.0     0.0        0.0\n",
       "4 2020-01-22          Gansu  Mainland China        0.0     0.0        0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "md = corona.get_group_ts('MD')\n",
    "md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall Stats to Calculate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-03T19:25:01.098042Z",
     "start_time": "2020-07-03T19:25:01.052778Z"
    }
   },
   "outputs": [],
   "source": [
    "# df = corona.df_us.copy()\n",
    "\n",
    "# ## Report Total Cases\n",
    "# total_cases = df.groupby('state').sum()[['Confirmed','Deaths']]\n",
    "# total_cases.sort_values('Confirmed',0,0).head(20).style.bar(['Deaths','Confirmed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  📕Covid Tracking Project Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://covidtracking.com/api\n",
    "\n",
    "`/api/v1/states/{state}/screenshots.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-03T19:25:01.145626Z",
     "start_time": "2020-07-03T19:25:01.099521Z"
    }
   },
   "outputs": [],
   "source": [
    "from fsds.imports import *\n",
    "\n",
    "pd.set_option('display.max_columns',0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get US Daily\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-03T19:25:01.193763Z",
     "start_time": "2020-07-03T19:25:01.146965Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import requests\n",
    "import json,urllib\n",
    "# todays_date = dt.datetime.now().strftime('%m%d%Y')\n",
    "\n",
    "# base_url = f\"http://covidtracking.com\"\n",
    "# # state='ny'\n",
    "# # url = f\"http://covidtracking.com/api/v1/states/{state}/screenshots.json\"\n",
    "# us_daily_url = '/api/v1/us/daily.csv'\n",
    "# states_daily_url = '/api/v1/states/daily.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📦 class `CovidTrackingProject`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-03T19:25:01.239748Z",
     "start_time": "2020-07-03T19:25:01.195122Z"
    }
   },
   "outputs": [],
   "source": [
    "from functions import CovidTrackingProject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-03T19:25:13.057910Z",
     "start_time": "2020-07-03T19:25:12.499662Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] DOWNLOADING DATASETS FROM COVID TRACKING PROJECT\n",
      "\thttps://covidtracking.com/data\n",
      "\t- File saved as: \"New Data/states_metadata.csv\"\n",
      "\t- File saved as: \"New Data/us.csv\"\n",
      "\t- File saved as: \"New Data/states.csv\"\n",
      "states\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "------------------------------------------------------------\n",
       "[i] CovidTrackingProject Contents:\n",
       "------------------------------------------------------------\n",
       "\n",
       "METHODS:\n",
       "\tdownload_state_daily\n",
       "\tdownload_state_meta\n",
       "\tdownload_us_daily\n",
       "\tget_csv_save_load\n",
       "\tget_group_ts\n",
       "\thelp\n",
       "\n",
       "ATTRIBUTES\n",
       "\tbase_folder\n",
       "\tbase_url\n",
       "\tcolumns\n",
       "\tcolumns_us\n",
       "\tdf\n",
       "\tdf_states\n",
       "\tdf_states_metadata\n",
       "\tdf_us\n",
       "\turls"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid=CovidTrackingProject(download=True,verbose=True)\n",
    "covid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-03T19:25:24.463049Z",
     "start_time": "2020-07-03T19:25:24.344655Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>pending</th>\n",
       "      <th>hospitalizedCurrently</th>\n",
       "      <th>hospitalizedCumulative</th>\n",
       "      <th>inIcuCurrently</th>\n",
       "      <th>inIcuCumulative</th>\n",
       "      <th>onVentilatorCurrently</th>\n",
       "      <th>onVentilatorCumulative</th>\n",
       "      <th>recovered</th>\n",
       "      <th>dataQualityGrade</th>\n",
       "      <th>lastUpdateEt</th>\n",
       "      <th>dateModified</th>\n",
       "      <th>checkTimeEt</th>\n",
       "      <th>death</th>\n",
       "      <th>hospitalized</th>\n",
       "      <th>dateChecked</th>\n",
       "      <th>totalTestsViral</th>\n",
       "      <th>positiveTestsViral</th>\n",
       "      <th>negativeTestsViral</th>\n",
       "      <th>positiveCasesViral</th>\n",
       "      <th>fips</th>\n",
       "      <th>positiveIncrease</th>\n",
       "      <th>negativeIncrease</th>\n",
       "      <th>total</th>\n",
       "      <th>totalTestResults</th>\n",
       "      <th>totalTestResultsIncrease</th>\n",
       "      <th>posNeg</th>\n",
       "      <th>deathIncrease</th>\n",
       "      <th>hospitalizedIncrease</th>\n",
       "      <th>hash</th>\n",
       "      <th>commercialScore</th>\n",
       "      <th>negativeRegularScore</th>\n",
       "      <th>negativeScore</th>\n",
       "      <th>positiveScore</th>\n",
       "      <th>score</th>\n",
       "      <th>grade</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-07-02</th>\n",
       "      <td>AK</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>114892.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>535.0</td>\n",
       "      <td>A</td>\n",
       "      <td>7/2/2020 00:00</td>\n",
       "      <td>2020-07-02T00:00:00Z</td>\n",
       "      <td>07/01 20:00</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-07-02T00:00:00Z</td>\n",
       "      <td>115909.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>1470</td>\n",
       "      <td>115909</td>\n",
       "      <td>115909</td>\n",
       "      <td>1509</td>\n",
       "      <td>115909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5ceb0f7088d68f2109723045dc01361a8be8f4aa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-02</th>\n",
       "      <td>AL</td>\n",
       "      <td>40111.0</td>\n",
       "      <td>379617.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>843.0</td>\n",
       "      <td>2835.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>826.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>468.0</td>\n",
       "      <td>22082.0</td>\n",
       "      <td>B</td>\n",
       "      <td>7/2/2020 11:00</td>\n",
       "      <td>2020-07-02T11:00:00Z</td>\n",
       "      <td>07/02 07:00</td>\n",
       "      <td>985.0</td>\n",
       "      <td>2835.0</td>\n",
       "      <td>2020-07-02T11:00:00Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39604.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1149</td>\n",
       "      <td>4626</td>\n",
       "      <td>419728</td>\n",
       "      <td>419728</td>\n",
       "      <td>5775</td>\n",
       "      <td>419728</td>\n",
       "      <td>13</td>\n",
       "      <td>32</td>\n",
       "      <td>bc01418e5a22f60d16bd176bbb53e937cef2dc5f</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-02</th>\n",
       "      <td>AR</td>\n",
       "      <td>22075.0</td>\n",
       "      <td>301912.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>272.0</td>\n",
       "      <td>1477.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>15698.0</td>\n",
       "      <td>A</td>\n",
       "      <td>7/2/2020 14:46</td>\n",
       "      <td>2020-07-02T14:46:00Z</td>\n",
       "      <td>07/02 10:46</td>\n",
       "      <td>279.0</td>\n",
       "      <td>1477.0</td>\n",
       "      <td>2020-07-02T14:46:00Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22075.0</td>\n",
       "      <td>5</td>\n",
       "      <td>878</td>\n",
       "      <td>8251</td>\n",
       "      <td>323987</td>\n",
       "      <td>323987</td>\n",
       "      <td>9129</td>\n",
       "      <td>323987</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>2413f6ff37227446a9c86921de099b46c163315f</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-02</th>\n",
       "      <td>AS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>696.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>6/27/2020 00:00</td>\n",
       "      <td>2020-06-27T00:00:00Z</td>\n",
       "      <td>06/26 20:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-06-27T00:00:00Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>696</td>\n",
       "      <td>696</td>\n",
       "      <td>0</td>\n",
       "      <td>696</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2f4ba1329beda94564e2d27052e2b97d2e3c99ca</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-02</th>\n",
       "      <td>AZ</td>\n",
       "      <td>87425.0</td>\n",
       "      <td>473414.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2938.0</td>\n",
       "      <td>4916.0</td>\n",
       "      <td>723.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>488.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10137.0</td>\n",
       "      <td>A+</td>\n",
       "      <td>7/2/2020 00:00</td>\n",
       "      <td>2020-07-02T00:00:00Z</td>\n",
       "      <td>07/01 20:00</td>\n",
       "      <td>1757.0</td>\n",
       "      <td>4916.0</td>\n",
       "      <td>2020-07-02T00:00:00Z</td>\n",
       "      <td>560384.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86970.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3333</td>\n",
       "      <td>7910</td>\n",
       "      <td>560839</td>\n",
       "      <td>560839</td>\n",
       "      <td>11243</td>\n",
       "      <td>560839</td>\n",
       "      <td>37</td>\n",
       "      <td>79</td>\n",
       "      <td>4aaef59a1ee4088ad1086a7ac6f469b856ae402b</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-26</th>\n",
       "      <td>WA</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>760c3dc0f1be8778f30b6d200547f3b5ac745758</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-25</th>\n",
       "      <td>WA</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8c8515283dd7f193d5ec506f4d6ef8334bc50770</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-24</th>\n",
       "      <td>WA</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>01659896e63df6a3a877a4c826167fe0e44cb8a8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-23</th>\n",
       "      <td>WA</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>b8c2a13e67216abb871b61007e5a22ff3828a041</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-22</th>\n",
       "      <td>WA</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>301c9c7fcd3ba68317ad772d47547f0448d98531</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6681 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           state  positive  negative  ...  positiveScore  score  grade\n",
       "date                                  ...                             \n",
       "2020-07-02    AK    1017.0  114892.0  ...              0      0    NaN\n",
       "2020-07-02    AL   40111.0  379617.0  ...              0      0    NaN\n",
       "2020-07-02    AR   22075.0  301912.0  ...              0      0    NaN\n",
       "2020-07-02    AS       0.0     696.0  ...              0      0    NaN\n",
       "2020-07-02    AZ   87425.0  473414.0  ...              0      0    NaN\n",
       "...          ...       ...       ...  ...            ...    ...    ...\n",
       "2020-01-26    WA       2.0       0.0  ...              0      0    NaN\n",
       "2020-01-25    WA       2.0       0.0  ...              0      0    NaN\n",
       "2020-01-24    WA       2.0       0.0  ...              0      0    NaN\n",
       "2020-01-23    WA       2.0       0.0  ...              0      0    NaN\n",
       "2020-01-22    WA       2.0       0.0  ...              0      0    NaN\n",
       "\n",
       "[6681 rows x 38 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid.df_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-03T19:25:33.358051Z",
     "start_time": "2020-07-03T19:25:33.312185Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['states', 'positive', 'negative', 'pending', 'hospitalizedCurrently',\n",
       "       'hospitalizedCumulative', 'inIcuCurrently', 'inIcuCumulative',\n",
       "       'onVentilatorCurrently', 'onVentilatorCumulative', 'recovered',\n",
       "       'dateChecked', 'death', 'hospitalized', 'lastModified', 'total',\n",
       "       'totalTestResults', 'posNeg', 'deathIncrease', 'hospitalizedIncrease',\n",
       "       'negativeIncrease', 'positiveIncrease', 'totalTestResultsIncrease',\n",
       "       'hash'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_us = covid.df_us.copy()\n",
    "# sorted(list(df_us.columns))\n",
    "df_us.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-03T19:04:18.270830Z",
     "start_time": "2020-07-03T19:04:09.184Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_us['fips']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-03T19:25:46.570797Z",
     "start_time": "2020-07-03T19:25:46.526188Z"
    }
   },
   "outputs": [],
   "source": [
    "good_us_cols = ['dateChecked','death', 'hash', 'hospitalizedCumulative',\n",
    " 'hospitalizedCurrently','inIcuCumulative', 'inIcuCurrently',\n",
    " 'negative', 'onVentilatorCumulative', 'onVentilatorCurrently',\n",
    " 'pending','positive','recovered','states']\n",
    "\n",
    "dep_us_cols = ['hospitalized', 'lastModified', 'total', \n",
    "             'totalTestResults', 'posNeg', 'deathIncrease',\n",
    "            'hospitalizedIncrease', 'negativeIncrease', 'positiveIncrease', \n",
    "            'totalTestResultsIncrease']#[col for col in df_us.columns if col not in good_us_cols]\n",
    "# print(dep_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-03T19:25:58.514030Z",
     "start_time": "2020-07-03T19:25:58.433061Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dateChecked</th>\n",
       "      <th>death</th>\n",
       "      <th>hash</th>\n",
       "      <th>hospitalizedCumulative</th>\n",
       "      <th>hospitalizedCurrently</th>\n",
       "      <th>inIcuCumulative</th>\n",
       "      <th>inIcuCurrently</th>\n",
       "      <th>negative</th>\n",
       "      <th>onVentilatorCumulative</th>\n",
       "      <th>onVentilatorCurrently</th>\n",
       "      <th>pending</th>\n",
       "      <th>positive</th>\n",
       "      <th>recovered</th>\n",
       "      <th>states</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-07-02</th>\n",
       "      <td>2020-07-02T00:00:00Z</td>\n",
       "      <td>121487.0</td>\n",
       "      <td>b4ecc6c883b4b7f5eefc00cd90a06d68d98b1d2e</td>\n",
       "      <td>245722.0</td>\n",
       "      <td>37114.0</td>\n",
       "      <td>10816.0</td>\n",
       "      <td>5609.0</td>\n",
       "      <td>30734553</td>\n",
       "      <td>1041.0</td>\n",
       "      <td>2105.0</td>\n",
       "      <td>2208.0</td>\n",
       "      <td>2727628</td>\n",
       "      <td>781970.0</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-01</th>\n",
       "      <td>2020-07-01T00:00:00Z</td>\n",
       "      <td>120853.0</td>\n",
       "      <td>f2966df0f86a9c1441db7ec10133690a51db09b6</td>\n",
       "      <td>243846.0</td>\n",
       "      <td>35937.0</td>\n",
       "      <td>10752.0</td>\n",
       "      <td>5494.0</td>\n",
       "      <td>30152546</td>\n",
       "      <td>1027.0</td>\n",
       "      <td>2098.0</td>\n",
       "      <td>2604.0</td>\n",
       "      <td>2674813</td>\n",
       "      <td>729994.0</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-30</th>\n",
       "      <td>2020-06-30T00:00:00Z</td>\n",
       "      <td>120152.0</td>\n",
       "      <td>480e9c7356c3b9278e1276e93eba16989d51c51f</td>\n",
       "      <td>242408.0</td>\n",
       "      <td>34830.0</td>\n",
       "      <td>10669.0</td>\n",
       "      <td>5406.0</td>\n",
       "      <td>29584414</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>2044.0</td>\n",
       "      <td>2432.0</td>\n",
       "      <td>2621831</td>\n",
       "      <td>720631.0</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-29</th>\n",
       "      <td>2020-06-29T00:00:00Z</td>\n",
       "      <td>119556.0</td>\n",
       "      <td>1e5c023acc5e3dc40dfb5c8dcb85625f801ccba3</td>\n",
       "      <td>240826.0</td>\n",
       "      <td>33198.0</td>\n",
       "      <td>10542.0</td>\n",
       "      <td>5363.0</td>\n",
       "      <td>28979934</td>\n",
       "      <td>990.0</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>2194.0</td>\n",
       "      <td>2577473</td>\n",
       "      <td>705203.0</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-28</th>\n",
       "      <td>2020-06-28T00:00:00Z</td>\n",
       "      <td>119226.0</td>\n",
       "      <td>5a80c658c8584c128e199ee1f6a823f452739257</td>\n",
       "      <td>240156.0</td>\n",
       "      <td>32117.0</td>\n",
       "      <td>10473.0</td>\n",
       "      <td>5230.0</td>\n",
       "      <td>28447030</td>\n",
       "      <td>983.0</td>\n",
       "      <td>2077.0</td>\n",
       "      <td>2198.0</td>\n",
       "      <td>2540983</td>\n",
       "      <td>685164.0</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-26</th>\n",
       "      <td>2020-01-26T00:00:00Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>e1cf59ab48e1cf367c4a6798a508a23d9d36bd18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-25</th>\n",
       "      <td>2020-01-25T00:00:00Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bef2a1d5f2a13491e0e0369bbd46c10cdd12973b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-24</th>\n",
       "      <td>2020-01-24T00:00:00Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bfffe76fc0b7cf11efe8aecd3cc7b22598d77d61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-23</th>\n",
       "      <td>2020-01-23T00:00:00Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cee36ebf3174bf1df0daa36e1e8088a157406fad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-22</th>\n",
       "      <td>2020-01-22T00:00:00Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d538c99729d1fee626212d1878a100c1e1204a5f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     dateChecked     death  ... recovered  states\n",
       "date                                        ...                  \n",
       "2020-07-02  2020-07-02T00:00:00Z  121487.0  ...  781970.0      56\n",
       "2020-07-01  2020-07-01T00:00:00Z  120853.0  ...  729994.0      56\n",
       "2020-06-30  2020-06-30T00:00:00Z  120152.0  ...  720631.0      56\n",
       "2020-06-29  2020-06-29T00:00:00Z  119556.0  ...  705203.0      56\n",
       "2020-06-28  2020-06-28T00:00:00Z  119226.0  ...  685164.0      56\n",
       "...                          ...       ...  ...       ...     ...\n",
       "2020-01-26  2020-01-26T00:00:00Z       NaN  ...       NaN       1\n",
       "2020-01-25  2020-01-25T00:00:00Z       NaN  ...       NaN       1\n",
       "2020-01-24  2020-01-24T00:00:00Z       NaN  ...       NaN       1\n",
       "2020-01-23  2020-01-23T00:00:00Z       NaN  ...       NaN       1\n",
       "2020-01-22  2020-01-22T00:00:00Z       NaN  ...       NaN       1\n",
       "\n",
       "[163 rows x 14 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = covid.df_us[covid.columns_us['good']].copy()\n",
    "df[good_us_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-03T19:04:18.273607Z",
     "start_time": "2020-07-03T19:04:09.191Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "covid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-03T19:04:18.274757Z",
     "start_time": "2020-07-03T19:04:09.194Z"
    }
   },
   "outputs": [],
   "source": [
    "covid.US"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# APPENDIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-03T19:04:18.275603Z",
     "start_time": "2020-07-03T19:04:09.196Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Load in Fips Data\n",
    "fips = pd.read_csv('Reference Data/ZIP-COUNTY-FIPS_2018-03.csv')\n",
    "fips.groupby('STATE').get_group(\"NY\")['STCOUNTYFP'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-03T19:04:18.276686Z",
     "start_time": "2020-07-03T19:04:09.199Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fips.loc[fips['STCOUNTYFP']==36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-03T19:04:18.277538Z",
     "start_time": "2020-07-03T19:04:09.201Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df = covid.STATES\n",
    "df['fips']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-03T19:04:18.278485Z",
     "start_time": "2020-07-03T19:04:09.203Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# #     def __init__(self):\n",
    "# tracking = CovidTrackingProject()\n",
    "# states_daily = tracking.download_state_daily()\n",
    "# us_daily=tracking.download_us_daily()\n",
    "# state_meta = tracking.download_state_meta()\n",
    "# display(states_daily.head(),us_daily.head(),state_meta.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-03T19:04:18.279345Z",
     "start_time": "2020-07-03T19:04:09.205Z"
    },
    "hidden": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "covid = CovidTrackingProject(download=True)\n",
    "state_meta = covid.data['states_metadata']\n",
    "states_daily = covid.data['states']\n",
    "state_list = state_meta['state'].unique()\n",
    "states_daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-03T19:04:18.280393Z",
     "start_time": "2020-07-03T19:04:09.207Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pandas_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-03T19:04:18.281310Z",
     "start_time": "2020-07-03T19:04:09.210Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "report  = ProfileReport(states_daily)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## NOTES: COLUMNS TO PLOT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Basic Stats:\n",
    "    - death: cumulative total people died\n",
    "    - positive: total number people positive so far\n",
    "    - negative\n",
    "    - recovered\n",
    "    \n",
    "\n",
    "- Hospitalization:\n",
    "    - hospitalizedCumulative: total number hospital so far(recovered and dead)\n",
    "    - hospitalizedCurrently: \n",
    "    - hospitalizedIncrease\n",
    "\n",
    "\n",
    "- ICU:\n",
    "    - inIcuCumulative: total number hospital so far(recovered and dead)\n",
    "    - inIcuCurrently: \n",
    "    \n",
    "- Ventilator \n",
    "    - onVentilatorCumulative\n",
    "    - onVentilatorCurrently\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-03T19:04:18.282414Z",
     "start_time": "2020-07-03T19:04:09.212Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "covid.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-03T19:04:18.283298Z",
     "start_time": "2020-07-03T19:04:09.214Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "NY = states_daily.groupby('state').get_group('NY')[covid.columns['good']]\n",
    "NY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🗺Adding Mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-02T02:06:08.498706Z",
     "start_time": "2020-07-02T02:06:08.496433Z"
    }
   },
   "source": [
    "## Geocoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-03T19:04:18.284220Z",
     "start_time": "2020-07-03T19:04:09.218Z"
    }
   },
   "outputs": [],
   "source": [
    "df = corona.df_us\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-03T19:04:18.285103Z",
     "start_time": "2020-07-03T19:04:09.220Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install geopandas\n",
    "# !pip install geopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-03T19:04:18.286022Z",
     "start_time": "2020-07-03T19:04:09.222Z"
    }
   },
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "locator = Nominatim(user_agent=\"myGeocoder\")\n",
    "res = locator.geocode('Baltimore')\n",
    "res.latitude,res.longitude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-02T02:06:25.776409Z",
     "start_time": "2020-07-02T02:06:25.774464Z"
    }
   },
   "source": [
    "## Folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-03T19:04:18.286890Z",
     "start_time": "2020-07-03T19:04:09.225Z"
    }
   },
   "outputs": [],
   "source": [
    "# import folium\n",
    "# center = (res.latitude,res.longitude) #(resp['region']['center']['latitude'],resp['region']['center']['longitude'])\n",
    "\n",
    "# popup = folium.Popup(f\"Latitude={center[0]}, Longitude={center[1]}\")\n",
    "# marker = folium.Marker(center,popup)\n",
    "# mymap = folium.Map(center)\n",
    "# marker.add_to(mymap)\n",
    "# mymap"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python36964bit03393eb90e194b7a9fdc02111cc1aa9d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "232.719px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
